{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# Define paths to model files\n",
    "import os\n",
    "MODELS_DIR = 'models/'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = MODELS_DIR + 'model'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'\n",
    "MODEL_INPUT = MODELS_DIR + 'input.cc'\n",
    "MODEL_OUTPUT = MODELS_DIR + 'output.cc'\n",
    "INPUT_DATA_NPY= MODELS_DIR + 'input_data.npy'\n",
    "OUTPUT_DATA_NPY= MODELS_DIR + 'output_data.npy'\n",
    "!pip3 install tensorflow"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/panyj/.local/lib/python3.6/site-packages (2.4.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/panyj/.local/lib/python3.6/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /home/panyj/.local/lib/python3.6/site-packages (from protobuf>=3.9.2->tensorflow) (57.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/panyj/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/panyj/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/panyj/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/panyj/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (1.30.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/panyj/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/panyj/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/panyj/.local/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/panyj/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/panyj/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/panyj/.local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2018.1.18)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.22)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/panyj/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# TensorFlow is an open source machine learning library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras is TensorFlow's high-level API for deep learning\n",
    "# Numpy is a math library\n",
    "import numpy as np\n",
    "# Pandas is a data manipulation library \n",
    "import pandas as pd\n",
    "# Matplotlib is a graphing library\n",
    "import matplotlib.pyplot as plt\n",
    "# Math is Python's math library\n",
    "import math\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Activation, Conv2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for experiment reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Design the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "\n",
    "#all_cnn_net\n",
    "# https://github.com/AnuragGorkar/Image_Recognition_using_AllCNN_architechture/blob/master/Image_Recognition_using_AllCNN_architechture.ipynb\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding = \"same\", input_shape = (32, 32, 3))) #----> 1 #n,h,w,c\n",
    "model.add(Activation('relu')) #----> 1\n",
    "\n",
    "    # INTERMEDIATE MODEL LAYERS\n",
    "model.add(Conv2D(96, (3, 3), padding = \"same\")) #----> 2\n",
    "model.add(Activation('relu')) #----> 2\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding = \"same\", strides = (2,2))) #----> 3\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(192, (3,3), padding = \"same\")) #----> 4\n",
    "model.add(Activation('relu')) #----> 4\n",
    "\n",
    "model.add(Conv2D(192, (3,3), padding = \"same\")) #----> 5\n",
    "model.add(Activation('relu')) #----> 5\n",
    "\n",
    "model.add(Conv2D(192, (3,3), padding = \"same\", strides = (2,2))) #----> 6\n",
    "model.add(Dropout(0.5)) #----> 6\n",
    "\n",
    "model.add(Conv2D(192, (3,3),padding = \"same\")) #----> 7\n",
    "model.add(Activation('relu')) #----> 7\n",
    "\n",
    "model.add(Conv2D(192, (1,1),padding = \"valid\")) #----> 8\n",
    "model.add(Activation('relu')) #----> 8\n",
    "\n",
    "model.add(Conv2D(10, (1,1),padding = \"valid\")) #----> 9\n",
    "model.add(Activation('relu')) #----> 9\n",
    "\n",
    "# ADD GLOBAL AVERAGE POOLING LAYER WITH SOFTMAX\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax'))\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 8, 8, 10)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "model_select = Sequential()\n",
    "\n",
    "model_select.add(Conv2D(96, (3, 3), padding = \"same\", input_shape = (32, 32, 3))) #----> 1 #n,h,w,c\n",
    "model_select.add(Activation('relu')) #----> 1\n",
    "\n",
    "print (model_select.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_63 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 32, 32, 96)        0         \n",
      "=================================================================\n",
      "Total params: 2,688\n",
      "Trainable params: 2,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Train Model (skip now)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "#(x_train, y_train),(x_test, y_test) = cifar10.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "model_select.save(MODEL_TF)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: models/model/assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: models/model/assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Generate a TensorFlow Lite Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 1. Generate Models with or without Quantization\n",
    "We now have an acceptably accurate model. We'll use the TensorFlow Lite Converter to convert the model into a special, space-efficient format for use on memory-constrained devices.\n",
    "\n",
    "Since this model is going to be deployed on a microcontroller, we want it to be as tiny as possible! One technique for reducing the size of a model is called quantization. It reduces the precision of the model's weights, and possibly the activations (output of each layer) as well, which saves memory, often without much impact on accuracy. Quantized models also run faster, since the calculations required are simpler.\n",
    "\n",
    "In the following cell, we'll convert the model twice: once with quantization, once without"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "      data = np.random.rand(1, 32, 32, 3)\n",
    "      yield [data.astype(np.float32)]\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "#converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7264"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate a TensorFlow Lite for Microcontrollers Model\n",
    "Convert the TensorFlow Lite quantized model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# Install xxd if it is not available\n",
    "#!apt-get update && apt-get -qq install xxd\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "# Update variable names\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# Reference: https://www.tensorflow.org/lite/performance/post_training_quantization\n",
    "interpreter = tf.lite.Interpreter(model_path=str(MODEL_TFLITE))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "input_data = np.random.rand(1, 32, 32, 3).astype(np.int8)\n",
    "# Check if the input type is quantized, then rescale input data to uint8\n",
    "if input_details['dtype'] == np.uint8:\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    input_data = input_data / input_scale + input_zero_point\n",
    "\n",
    "interpreter.set_tensor(input_details[\"index\"], input_data)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[\"index\"])[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "# save input and expected output\n",
    "np.save(INPUT_DATA_NPY, input_data)\n",
    "np.save(OUTPUT_DATA_NPY, input_data)\n",
    "!xxd -i {INPUT_DATA_NPY} > {MODEL_INPUT}\n",
    "!xxd -i {OUTPUT_DATA_NPY} > {MODEL_OUTPUT}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}